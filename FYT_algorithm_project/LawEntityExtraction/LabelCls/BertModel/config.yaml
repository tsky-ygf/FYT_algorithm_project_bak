is_debug: False

# training args
train_batch_size: 32
eval_batch_size: 8
lr_scheduler_type: "linear" # "linear", "cosine", "cosine_with_restarts", "polynomial", "constant", "constant_with_warmup"
num_warmup_steps: 0
gradient_accumulation_steps: 1
weight_decay: 0.01
learning_rate: 0.00002 # 0.00005 0.00001
num_train_epochs: 20
eval_every_number_of_epoch: 1
early_stop_patience: 20

# model args
num_labels: 3
max_len: 256
dropout: 0.1
feature_dim: 256

#pre_train_tokenizer: "model/language_model/chinese-roberta-wwm-ext/"
#pre_train_model: "model/language_model/lawformer"

pre_train_tokenizer: "model/language_model/bert-base-chinese/"
pre_train_model: "model/language_model/bert-base-chinese"

train_data_path: "LawEntityExtraction/data/bert/pay_child_support/train.json"
dev_data_path: "LawEntityExtraction/data/bert/pay_child_support/dev.json"
test_data_path: "LawEntityExtraction/data/bert/marriage/spec_dev_ner0.json"

label_mapping_path: "LawEntityExtraction/data/bert/pay_child_support/pay_child_support.csv"

# output model path
output_dir: "model/marriage_bert/pay_child_support/"