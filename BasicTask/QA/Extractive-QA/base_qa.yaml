LogArguments:
  is_debug: True
  log_level: "DEBUG"

TrainingArguments:
  train_batch_size: 32
  eval_batch_size: 4
  lr_scheduler_type: "linear"
  learning_rate: 0.00005
  num_train_epochs: 20
  accelerator_params:
    fp16: True

ModelArguments:
  model_name_or_path: "model/language_model/bert-base-chinese"
#  tokenizer_name: "model/language_model/chinese-roberta-wwm-ext/"
  max_length: 512

DataTrainingArguments:
  train_data_path: "data/huggingface/squad/squad1.1/train-v1.1.json"
  dev_data_path: "data/huggingface/squad/squad1.1/dev-v1.1.json"
  test_data_path: "data/huggingface/squad/squad1.1/dev-v1.1.json"
  output_dir: "model/train_result/Extractive-QA/"